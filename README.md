# ğŸ§  GenAI-LLMs: Generative AI & Large Language Models Repository

<div align="center">

[![GitHub](https://img.shields.io/badge/GitHub-Repository-black?style=flat-square&logo=github)](https://github.com/MOHITH4W5/GenAI-LLMs)
[![Python](https://img.shields.io/badge/Python-3.9+-blue?style=flat-square&logo=python)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-Framework-red?style=flat-square&logo=pytorch)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)](LICENSE)

**Advanced exploration and implementation of Generative AI, LLMs, NLP, and Computer Vision techniques**

[Features](#features) â€¢ [Projects](#projects) â€¢ [Installation](#installation) â€¢ [Quick Start](#quick-start) â€¢ [Contributing](#contributing)

</div>

---

## ğŸ“‹ Overview

This repository contains comprehensive implementations and experiments in:

- **Generative AI** - Text generation, image generation, and multimodal models
- **Large Language Models (LLMs)** - Fine-tuning, RAG systems, prompt engineering
- **Natural Language Processing (NLP)** - Text processing, sentiment analysis, embeddings
- **Computer Vision (CV)** - Object detection, image classification, segmentation
- **MLOps & Deployment** - Model optimization, containerization, deployment strategies

## âœ¨ Features

- ğŸ¤– **LLM Fine-Tuning** - Complete pipelines for model adaptation
- ğŸ”„ **RAG Systems** - Retrieval-Augmented Generation implementations
- ğŸ“Š **Prompt Engineering** - Advanced prompting strategies and techniques
- ğŸ¯ **NLP Projects** - Complete NLP workflow examples
- ğŸ–¼ï¸ **Computer Vision** - Image processing and analysis tools
- âš¡ **Optimization** - Model quantization and performance tuning
- ğŸ³ **Deployment Ready** - Docker and production configurations
- ğŸ“š **Comprehensive Documentation** - Detailed guides and tutorials

## ğŸ“ Project Structure

```
GenAI-LLMs/
â”œâ”€â”€ llm/                          # Large Language Models
â”‚   â”œâ”€â”€ fine_tuning/             # LLM fine-tuning scripts
â”‚   â”œâ”€â”€ rag_systems/             # RAG implementations
â”‚   â”œâ”€â”€ prompt_engineering/      # Prompt optimization
â”‚   â””â”€â”€ inference/               # Model inference
â”‚
â”œâ”€â”€ nlp/                          # Natural Language Processing
â”‚   â”œâ”€â”€ text_generation/         # Text generation models
â”‚   â”œâ”€â”€ embeddings/              # Embedding techniques
â”‚   â”œâ”€â”€ sentiment_analysis/      # Sentiment analysis models
â”‚   â””â”€â”€ translation/             # Machine translation
â”‚
â”œâ”€â”€ cv/                           # Computer Vision
â”‚   â”œâ”€â”€ object_detection/        # Detection models
â”‚   â”œâ”€â”€ classification/          # Image classification
â”‚   â”œâ”€â”€ segmentation/            # Segmentation tasks
â”‚   â””â”€â”€ utils/                   # CV utilities
â”‚
â”œâ”€â”€ utils/                        # Shared utilities
â”‚   â”œâ”€â”€ data_processing/         # Data preprocessing
â”‚   â”œâ”€â”€ model_utils/             # Model utilities
â”‚   â””â”€â”€ evaluation/              # Evaluation metrics
â”‚
â”œâ”€â”€ notebooks/                    # Jupyter notebooks
â”œâ”€â”€ configs/                      # Configuration files
â”œâ”€â”€ docker/                       # Docker configurations
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ README.md                     # This file
â””â”€â”€ LICENSE                       # License
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- CUDA 11.0+ (for GPU support)
- pip or conda

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/MOHITH4W5/GenAI-LLMs.git
   cd GenAI-LLMs
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Verify installation**
   ```bash
   python -c "import torch; print(f'PyTorch {torch.__version__}')"
   ```

## ğŸ’¡ Key Modules

### LLM Fine-Tuning
Complete pipelines for fine-tuning Large Language Models using:
- LoRA (Low-Rank Adaptation)
- QLoRA (Quantized LoRA)
- Full fine-tuning
- Multi-GPU training

### RAG Systems
Retrieval-Augmented Generation for:
- Document retrieval
- Context-aware generation
- Knowledge base integration

### Prompt Engineering
- Few-shot prompting
- Chain-of-thought reasoning
- Prompt optimization
- Template-based approaches

### NLP Projects
- Text generation
- Sentiment analysis
- Named entity recognition
- Question answering

## ğŸ“¦ Dependencies

**Core Libraries:**
- `torch` - Deep learning framework
- `transformers` - Pre-trained models
- `numpy` - Numerical computing
- `pandas` - Data manipulation
- `scikit-learn` - ML utilities

**Optional:**
- `CUDA Toolkit` - GPU acceleration
- `jupyter` - Notebooks
- `wandb` - Experiment tracking
- `tensorboard` - Visualization

## ğŸ¯ Getting Started

### Run Your First LLM Fine-Tuning

```bash
cd llm/fine_tuning
python train.py --config config.yaml
```

### Explore RAG System

```bash
cd llm/rag_systems
python rag_pipeline.py
```

### Try NLP Tasks

```bash
cd nlp/text_generation
python generate.py --model gpt2
```

## ğŸ“š Documentation

- [LLM Guide](./docs/llm_guide.md)
- [NLP Tutorial](./docs/nlp_tutorial.md)
- [Computer Vision Guide](./docs/cv_guide.md)
- [Deployment Guide](./docs/deployment.md)
- [API Reference](./docs/api_reference.md)

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Commit changes
4. Push to branch
5. Open a Pull Request

See [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.

## ğŸ“ Examples

### Fine-tune Llama 2
```python
from llm.fine_tuning import LlamaTuner

tuner = LlamaTuner(model_id="meta-llama/Llama-2-7b")
tuner.train(train_data, epochs=3, batch_size=16)
tuner.save("./finetuned_llama")
```

### Build RAG System
```python
from llm.rag_systems import RAGPipeline

rag = RAGPipeline(model="gpt-3.5-turbo")
rag.add_documents(documents)
response = rag.query("Your question here")
print(response)
```

## ğŸ“Š Benchmarks

- Llama 2 Fine-tuning: 2.5 hours on A100
- RAG System: 0.2s latency per query
- NLP Classification: 95%+ accuracy

## ğŸ”— Resources

- [Hugging Face Transformers](https://huggingface.co/transformers/)
- [PyTorch Documentation](https://pytorch.org/docs/)
- [OpenAI API](https://openai.com/api/)
- [LangChain](https://langchain.com/)

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file

## ğŸ‘¤ Author

**Mohith**
- GitHub: [@MOHITH4W5](https://github.com/MOHITH4W5)
- Portfolio: [View](https://github.com/MOHITH4W5/portfolio)

## ğŸ™ Acknowledgments

- Hugging Face for transformers library
- PyTorch team for the deep learning framework
- Open source community for contributions

---

<div align="center">

**â­ If you find this repository useful, please consider giving it a star!**

Made with ğŸ’» for AI/ML enthusiasts and researchers

</div>
